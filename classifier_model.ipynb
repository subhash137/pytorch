{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=4,out_features=1)\n",
    "        \n",
    "    def  forward(self,x : torch.tensor) -> torch.Tensor:\n",
    "        return torch.sigmoid(self.linear_layer(x))\n",
    "    \n",
    "def plotting(x,y,predictions = None):\n",
    "    plt.scatter(x,y,c = \"r\")\n",
    "    if predictions is not None:\n",
    "        plt.scatter(x,predictions,c = \"b\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4]) torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "# List of inputs (features of iris flowers)\n",
    "X = torch.tensor([\n",
    "    [5.1, 3.5, 1.4, 0.2],\n",
    "    [6.2, 2.8, 4.8, 1.8],\n",
    "    [7.9, 3.8, 6.4, 2.0],\n",
    "    [4.9, 3.0, 1.4, 0.2],\n",
    "    [6.7, 3.1, 4.4, 1.4],\n",
    "    [5.8, 2.6, 4.0, 1.2],\n",
    "    [4.8, 3.4, 1.9, 0.2],\n",
    "    [6.3, 3.3, 6.0, 2.5],\n",
    "    [5.4, 3.9, 1.7, 0.4],\n",
    "    [6.1, 2.9, 4.7, 1.4]\n",
    "],dtype = torch.float32)\n",
    "\n",
    "# List of outputs (binary class labels: 0 or 1)\n",
    "y = torch.tensor([0, 1, 1, 0, 1, 1, 0, 1, 0, 1],dtype = torch.float32).unsqueeze(dim = 1)\n",
    "\n",
    "X.to(device)\n",
    "y.to(device)\n",
    "\n",
    "split_percentage = int(0.8*len(X))\n",
    "X_train , y_train = X[:split_percentage], y[:split_percentage]\n",
    "X_test,y_test = X[split_percentage:], y[split_percentage:]\n",
    "scaler = StandardScaler()\n",
    "X_train = torch.tensor(scaler.fit_transform(X_train),dtype = torch.float32)\n",
    "X_test = torch.tensor(scaler.transform(X_test),dtype=torch.float32)\n",
    "\n",
    "X_train.to(device)\n",
    "X_test.to(device)\n",
    "y_train.to(device)\n",
    "y_test.to(device)\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.3823,  0.4150, -0.1171,  0.4593]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1096], requires_grad=True)]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = LogisticRegressionModel()\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params = model.parameters(),lr = 0.01,momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3829],\n",
      "        [0.4532],\n",
      "        [0.8345],\n",
      "        [0.2455],\n",
      "        [0.5387],\n",
      "        [0.3002],\n",
      "        [0.3233],\n",
      "        [0.6734]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 0, Train Loss: 0.5430772304534912, Test Loss: 0.8243038058280945\n",
      "tensor([[0.3807],\n",
      "        [0.4552],\n",
      "        [0.8357],\n",
      "        [0.2443],\n",
      "        [0.5401],\n",
      "        [0.3013],\n",
      "        [0.3214],\n",
      "        [0.6755]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 1, Train Loss: 0.5401927828788757, Test Loss: 0.8160194158554077\n",
      "tensor([[0.3766],\n",
      "        [0.4590],\n",
      "        [0.8380],\n",
      "        [0.2420],\n",
      "        [0.5426],\n",
      "        [0.3034],\n",
      "        [0.3178],\n",
      "        [0.6794]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 2, Train Loss: 0.5347611308097839, Test Loss: 0.8043475151062012\n",
      "tensor([[0.3707],\n",
      "        [0.4644],\n",
      "        [0.8412],\n",
      "        [0.2387],\n",
      "        [0.5463],\n",
      "        [0.3064],\n",
      "        [0.3128],\n",
      "        [0.6849]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 3, Train Loss: 0.5271245837211609, Test Loss: 0.7897804379463196\n",
      "tensor([[0.3634],\n",
      "        [0.4713],\n",
      "        [0.8451],\n",
      "        [0.2346],\n",
      "        [0.5508],\n",
      "        [0.3102],\n",
      "        [0.3066],\n",
      "        [0.6918]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 4, Train Loss: 0.517620325088501, Test Loss: 0.7727914452552795\n",
      "tensor([[0.3548],\n",
      "        [0.4795],\n",
      "        [0.8497],\n",
      "        [0.2299],\n",
      "        [0.5562],\n",
      "        [0.3147],\n",
      "        [0.2993],\n",
      "        [0.6997]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 5, Train Loss: 0.5065723657608032, Test Loss: 0.7538279294967651\n",
      "tensor([[0.3452],\n",
      "        [0.4888],\n",
      "        [0.8547],\n",
      "        [0.2247],\n",
      "        [0.5623],\n",
      "        [0.3200],\n",
      "        [0.2912],\n",
      "        [0.7087]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 6, Train Loss: 0.4942852258682251, Test Loss: 0.7333056926727295\n",
      "tensor([[0.3347],\n",
      "        [0.4991],\n",
      "        [0.8601],\n",
      "        [0.2190],\n",
      "        [0.5691],\n",
      "        [0.3258],\n",
      "        [0.2824],\n",
      "        [0.7183]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 7, Train Loss: 0.48103997111320496, Test Loss: 0.7116066217422485\n",
      "tensor([[0.3237],\n",
      "        [0.5102],\n",
      "        [0.8657],\n",
      "        [0.2131],\n",
      "        [0.5763],\n",
      "        [0.3323],\n",
      "        [0.2732],\n",
      "        [0.7285]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 8, Train Loss: 0.46709123253822327, Test Loss: 0.689075767993927\n",
      "tensor([[0.3122],\n",
      "        [0.5220],\n",
      "        [0.8713],\n",
      "        [0.2069],\n",
      "        [0.5840],\n",
      "        [0.3392],\n",
      "        [0.2636],\n",
      "        [0.7390]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 9, Train Loss: 0.45266589522361755, Test Loss: 0.6660213470458984\n",
      "tensor([[0.3004],\n",
      "        [0.5344],\n",
      "        [0.8770],\n",
      "        [0.2007],\n",
      "        [0.5920],\n",
      "        [0.3466],\n",
      "        [0.2538],\n",
      "        [0.7497]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 10, Train Loss: 0.4379628002643585, Test Loss: 0.6427136063575745\n",
      "tensor([[0.2885],\n",
      "        [0.5472],\n",
      "        [0.8827],\n",
      "        [0.1944],\n",
      "        [0.6002],\n",
      "        [0.3544],\n",
      "        [0.2439],\n",
      "        [0.7605]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 11, Train Loss: 0.4231533408164978, Test Loss: 0.6193867921829224\n",
      "tensor([[0.2765],\n",
      "        [0.5604],\n",
      "        [0.8883],\n",
      "        [0.1881],\n",
      "        [0.6087],\n",
      "        [0.3626],\n",
      "        [0.2340],\n",
      "        [0.7713]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 12, Train Loss: 0.408382773399353, Test Loss: 0.5962402820587158\n",
      "tensor([[0.2647],\n",
      "        [0.5738],\n",
      "        [0.8936],\n",
      "        [0.1819],\n",
      "        [0.6172],\n",
      "        [0.3711],\n",
      "        [0.2243],\n",
      "        [0.7819]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 13, Train Loss: 0.393771767616272, Test Loss: 0.5734403729438782\n",
      "tensor([[0.2531],\n",
      "        [0.5873],\n",
      "        [0.8988],\n",
      "        [0.1758],\n",
      "        [0.6259],\n",
      "        [0.3798],\n",
      "        [0.2148],\n",
      "        [0.7922]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 14, Train Loss: 0.3794187903404236, Test Loss: 0.5511232018470764\n",
      "tensor([[0.2417],\n",
      "        [0.6008],\n",
      "        [0.9038],\n",
      "        [0.1700],\n",
      "        [0.6345],\n",
      "        [0.3889],\n",
      "        [0.2055],\n",
      "        [0.8023]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 15, Train Loss: 0.36540234088897705, Test Loss: 0.5293970704078674\n",
      "tensor([[0.2307],\n",
      "        [0.6143],\n",
      "        [0.9086],\n",
      "        [0.1643],\n",
      "        [0.6431],\n",
      "        [0.3981],\n",
      "        [0.1965],\n",
      "        [0.8120]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 16, Train Loss: 0.3517829477787018, Test Loss: 0.5083458423614502\n",
      "tensor([[0.2201],\n",
      "        [0.6277],\n",
      "        [0.9131],\n",
      "        [0.1588],\n",
      "        [0.6517],\n",
      "        [0.4075],\n",
      "        [0.1879],\n",
      "        [0.8213]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 17, Train Loss: 0.3386058509349823, Test Loss: 0.4880314767360687\n",
      "tensor([[0.2099],\n",
      "        [0.6409],\n",
      "        [0.9174],\n",
      "        [0.1535],\n",
      "        [0.6601],\n",
      "        [0.4170],\n",
      "        [0.1796],\n",
      "        [0.8303]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 18, Train Loss: 0.32590287923812866, Test Loss: 0.4684965908527374\n",
      "tensor([[0.2001],\n",
      "        [0.6538],\n",
      "        [0.9214],\n",
      "        [0.1485],\n",
      "        [0.6684],\n",
      "        [0.4267],\n",
      "        [0.1717],\n",
      "        [0.8388]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 19, Train Loss: 0.3136948049068451, Test Loss: 0.44976794719696045\n",
      "tensor([[0.1908],\n",
      "        [0.6665],\n",
      "        [0.9251],\n",
      "        [0.1437],\n",
      "        [0.6766],\n",
      "        [0.4364],\n",
      "        [0.1641],\n",
      "        [0.8468]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 20, Train Loss: 0.3019929826259613, Test Loss: 0.43185847997665405\n",
      "tensor([[0.1820],\n",
      "        [0.6788],\n",
      "        [0.9287],\n",
      "        [0.1391],\n",
      "        [0.6845],\n",
      "        [0.4461],\n",
      "        [0.1570],\n",
      "        [0.8544]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 21, Train Loss: 0.29080092906951904, Test Loss: 0.41476985812187195\n",
      "tensor([[0.1736],\n",
      "        [0.6907],\n",
      "        [0.9320],\n",
      "        [0.1348],\n",
      "        [0.6923],\n",
      "        [0.4558],\n",
      "        [0.1502],\n",
      "        [0.8616]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 22, Train Loss: 0.2801162302494049, Test Loss: 0.3984944224357605\n",
      "tensor([[0.1657],\n",
      "        [0.7023],\n",
      "        [0.9351],\n",
      "        [0.1307],\n",
      "        [0.6999],\n",
      "        [0.4656],\n",
      "        [0.1438],\n",
      "        [0.8684]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 23, Train Loss: 0.2699313461780548, Test Loss: 0.3830172121524811\n",
      "tensor([[0.1582],\n",
      "        [0.7134],\n",
      "        [0.9380],\n",
      "        [0.1268],\n",
      "        [0.7072],\n",
      "        [0.4752],\n",
      "        [0.1378],\n",
      "        [0.8747]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 24, Train Loss: 0.26023492217063904, Test Loss: 0.3683176040649414\n",
      "tensor([[0.1512],\n",
      "        [0.7242],\n",
      "        [0.9407],\n",
      "        [0.1231],\n",
      "        [0.7144],\n",
      "        [0.4848],\n",
      "        [0.1321],\n",
      "        [0.8807]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 25, Train Loss: 0.2510128617286682, Test Loss: 0.354370653629303\n",
      "tensor([[0.1446],\n",
      "        [0.7345],\n",
      "        [0.9432],\n",
      "        [0.1196],\n",
      "        [0.7213],\n",
      "        [0.4944],\n",
      "        [0.1267],\n",
      "        [0.8863]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 26, Train Loss: 0.2422487735748291, Test Loss: 0.3411482274532318\n",
      "tensor([[0.1383],\n",
      "        [0.7444],\n",
      "        [0.9456],\n",
      "        [0.1164],\n",
      "        [0.7279],\n",
      "        [0.5038],\n",
      "        [0.1217],\n",
      "        [0.8916]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 27, Train Loss: 0.2339249849319458, Test Loss: 0.3286203145980835\n",
      "tensor([[0.1325],\n",
      "        [0.7539],\n",
      "        [0.9477],\n",
      "        [0.1133],\n",
      "        [0.7344],\n",
      "        [0.5131],\n",
      "        [0.1169],\n",
      "        [0.8965]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 28, Train Loss: 0.22602272033691406, Test Loss: 0.3167553246021271\n",
      "tensor([[0.1270],\n",
      "        [0.7630],\n",
      "        [0.9498],\n",
      "        [0.1104],\n",
      "        [0.7406],\n",
      "        [0.5223],\n",
      "        [0.1125],\n",
      "        [0.9011]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 29, Train Loss: 0.2185228168964386, Test Loss: 0.3055213689804077\n",
      "tensor([[0.1219],\n",
      "        [0.7716],\n",
      "        [0.9517],\n",
      "        [0.1077],\n",
      "        [0.7466],\n",
      "        [0.5313],\n",
      "        [0.1083],\n",
      "        [0.9054]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 30, Train Loss: 0.21140584349632263, Test Loss: 0.29488617181777954\n",
      "tensor([[0.1170],\n",
      "        [0.7799],\n",
      "        [0.9535],\n",
      "        [0.1051],\n",
      "        [0.7524],\n",
      "        [0.5401],\n",
      "        [0.1044],\n",
      "        [0.9095]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 31, Train Loss: 0.2046526074409485, Test Loss: 0.28481802344322205\n",
      "tensor([[0.1125],\n",
      "        [0.7878],\n",
      "        [0.9551],\n",
      "        [0.1026],\n",
      "        [0.7580],\n",
      "        [0.5488],\n",
      "        [0.1007],\n",
      "        [0.9132]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 32, Train Loss: 0.1982441544532776, Test Loss: 0.2752857804298401\n",
      "tensor([[0.1082],\n",
      "        [0.7953],\n",
      "        [0.9567],\n",
      "        [0.1004],\n",
      "        [0.7633],\n",
      "        [0.5574],\n",
      "        [0.0972],\n",
      "        [0.9168]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 33, Train Loss: 0.19216196238994598, Test Loss: 0.2662592828273773\n",
      "tensor([[0.1042],\n",
      "        [0.8025],\n",
      "        [0.9581],\n",
      "        [0.0982],\n",
      "        [0.7685],\n",
      "        [0.5657],\n",
      "        [0.0939],\n",
      "        [0.9201]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 34, Train Loss: 0.18638819456100464, Test Loss: 0.2577093541622162\n",
      "tensor([[0.1004],\n",
      "        [0.8093],\n",
      "        [0.9595],\n",
      "        [0.0961],\n",
      "        [0.7735],\n",
      "        [0.5739],\n",
      "        [0.0909],\n",
      "        [0.9232]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 35, Train Loss: 0.18090559542179108, Test Loss: 0.24960815906524658\n",
      "tensor([[0.0969],\n",
      "        [0.8157],\n",
      "        [0.9608],\n",
      "        [0.0942],\n",
      "        [0.7782],\n",
      "        [0.5819],\n",
      "        [0.0880],\n",
      "        [0.9261]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 36, Train Loss: 0.17569772899150848, Test Loss: 0.24192899465560913\n",
      "tensor([[0.0936],\n",
      "        [0.8219],\n",
      "        [0.9620],\n",
      "        [0.0924],\n",
      "        [0.7828],\n",
      "        [0.5897],\n",
      "        [0.0852],\n",
      "        [0.9289]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 37, Train Loss: 0.1707487553358078, Test Loss: 0.23464658856391907\n",
      "tensor([[0.0904],\n",
      "        [0.8278],\n",
      "        [0.9631],\n",
      "        [0.0907],\n",
      "        [0.7872],\n",
      "        [0.5973],\n",
      "        [0.0827],\n",
      "        [0.9314]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 38, Train Loss: 0.16604375839233398, Test Loss: 0.22773689031600952\n",
      "tensor([[0.0875],\n",
      "        [0.8333],\n",
      "        [0.9642],\n",
      "        [0.0890],\n",
      "        [0.7915],\n",
      "        [0.6047],\n",
      "        [0.0802],\n",
      "        [0.9339]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 39, Train Loss: 0.16156861186027527, Test Loss: 0.22117742896080017\n",
      "tensor([[0.0847],\n",
      "        [0.8386],\n",
      "        [0.9652],\n",
      "        [0.0875],\n",
      "        [0.7956],\n",
      "        [0.6119],\n",
      "        [0.0779],\n",
      "        [0.9361]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 40, Train Loss: 0.15730983018875122, Test Loss: 0.21494674682617188\n",
      "tensor([[0.0820],\n",
      "        [0.8437],\n",
      "        [0.9661],\n",
      "        [0.0860],\n",
      "        [0.7995],\n",
      "        [0.6189],\n",
      "        [0.0758],\n",
      "        [0.9383]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 41, Train Loss: 0.15325473248958588, Test Loss: 0.20902474224567413\n",
      "tensor([[0.0796],\n",
      "        [0.8485],\n",
      "        [0.9670],\n",
      "        [0.0846],\n",
      "        [0.8033],\n",
      "        [0.6258],\n",
      "        [0.0737],\n",
      "        [0.9403]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 42, Train Loss: 0.14939139783382416, Test Loss: 0.20339274406433105\n",
      "tensor([[0.0772],\n",
      "        [0.8531],\n",
      "        [0.9678],\n",
      "        [0.0833],\n",
      "        [0.8069],\n",
      "        [0.6324],\n",
      "        [0.0718],\n",
      "        [0.9422]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 43, Train Loss: 0.1457085907459259, Test Loss: 0.1980329304933548\n",
      "tensor([[0.0750],\n",
      "        [0.8575],\n",
      "        [0.9686],\n",
      "        [0.0820],\n",
      "        [0.8104],\n",
      "        [0.6389],\n",
      "        [0.0699],\n",
      "        [0.9440]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 44, Train Loss: 0.14219574630260468, Test Loss: 0.19292879104614258\n",
      "tensor([[0.0729],\n",
      "        [0.8616],\n",
      "        [0.9694],\n",
      "        [0.0808],\n",
      "        [0.8138],\n",
      "        [0.6452],\n",
      "        [0.0682],\n",
      "        [0.9457]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 45, Train Loss: 0.1388428956270218, Test Loss: 0.1880648136138916\n",
      "tensor([[0.0709],\n",
      "        [0.8656],\n",
      "        [0.9701],\n",
      "        [0.0797],\n",
      "        [0.8170],\n",
      "        [0.6513],\n",
      "        [0.0665],\n",
      "        [0.9473]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 46, Train Loss: 0.13564077019691467, Test Loss: 0.1834266036748886\n",
      "tensor([[0.0690],\n",
      "        [0.8693],\n",
      "        [0.9707],\n",
      "        [0.0786],\n",
      "        [0.8202],\n",
      "        [0.6573],\n",
      "        [0.0649],\n",
      "        [0.9488]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 47, Train Loss: 0.13258057832717896, Test Loss: 0.17900054156780243\n",
      "tensor([[0.0672],\n",
      "        [0.8730],\n",
      "        [0.9714],\n",
      "        [0.0775],\n",
      "        [0.8232],\n",
      "        [0.6631],\n",
      "        [0.0634],\n",
      "        [0.9503]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 48, Train Loss: 0.129654198884964, Test Loss: 0.17477399110794067\n",
      "tensor([[0.0655],\n",
      "        [0.8764],\n",
      "        [0.9720],\n",
      "        [0.0766],\n",
      "        [0.8261],\n",
      "        [0.6687],\n",
      "        [0.0620],\n",
      "        [0.9516]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 49, Train Loss: 0.12685388326644897, Test Loss: 0.17073515057563782\n",
      "tensor([[0.0639],\n",
      "        [0.8797],\n",
      "        [0.9726],\n",
      "        [0.0756],\n",
      "        [0.8289],\n",
      "        [0.6742],\n",
      "        [0.0606],\n",
      "        [0.9529]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 50, Train Loss: 0.12417249381542206, Test Loss: 0.1668729931116104\n",
      "tensor([[0.0623],\n",
      "        [0.8828],\n",
      "        [0.9731],\n",
      "        [0.0747],\n",
      "        [0.8316],\n",
      "        [0.6795],\n",
      "        [0.0593],\n",
      "        [0.9542]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 51, Train Loss: 0.12160326540470123, Test Loss: 0.16317717730998993\n",
      "tensor([[0.0609],\n",
      "        [0.8858],\n",
      "        [0.9736],\n",
      "        [0.0738],\n",
      "        [0.8342],\n",
      "        [0.6846],\n",
      "        [0.0581],\n",
      "        [0.9553]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 52, Train Loss: 0.11913987994194031, Test Loss: 0.1596381664276123\n",
      "tensor([[0.0595],\n",
      "        [0.8887],\n",
      "        [0.9741],\n",
      "        [0.0730],\n",
      "        [0.8367],\n",
      "        [0.6896],\n",
      "        [0.0569],\n",
      "        [0.9565]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 53, Train Loss: 0.1167764961719513, Test Loss: 0.1562468409538269\n",
      "tensor([[0.0581],\n",
      "        [0.8914],\n",
      "        [0.9746],\n",
      "        [0.0722],\n",
      "        [0.8392],\n",
      "        [0.6945],\n",
      "        [0.0558],\n",
      "        [0.9575]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 54, Train Loss: 0.11450750380754471, Test Loss: 0.15299490094184875\n",
      "tensor([[0.0568],\n",
      "        [0.8941],\n",
      "        [0.9751],\n",
      "        [0.0714],\n",
      "        [0.8415],\n",
      "        [0.6993],\n",
      "        [0.0547],\n",
      "        [0.9585]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 55, Train Loss: 0.11232777684926987, Test Loss: 0.1498745083808899\n",
      "tensor([[0.0556],\n",
      "        [0.8966],\n",
      "        [0.9755],\n",
      "        [0.0707],\n",
      "        [0.8438],\n",
      "        [0.7039],\n",
      "        [0.0536],\n",
      "        [0.9595]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 56, Train Loss: 0.11023247241973877, Test Loss: 0.14687828719615936\n",
      "tensor([[0.0544],\n",
      "        [0.8990],\n",
      "        [0.9759],\n",
      "        [0.0699],\n",
      "        [0.8460],\n",
      "        [0.7083],\n",
      "        [0.0526],\n",
      "        [0.9604]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 57, Train Loss: 0.10821699351072311, Test Loss: 0.14399945735931396\n",
      "tensor([[0.0533],\n",
      "        [0.9013],\n",
      "        [0.9763],\n",
      "        [0.0692],\n",
      "        [0.8482],\n",
      "        [0.7127],\n",
      "        [0.0517],\n",
      "        [0.9613]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 58, Train Loss: 0.10627711564302444, Test Loss: 0.14123156666755676\n",
      "tensor([[0.0522],\n",
      "        [0.9036],\n",
      "        [0.9767],\n",
      "        [0.0686],\n",
      "        [0.8503],\n",
      "        [0.7169],\n",
      "        [0.0508],\n",
      "        [0.9622]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 59, Train Loss: 0.10440882295370102, Test Loss: 0.13856865465641022\n",
      "tensor([[0.0512],\n",
      "        [0.9057],\n",
      "        [0.9771],\n",
      "        [0.0679],\n",
      "        [0.8523],\n",
      "        [0.7211],\n",
      "        [0.0499],\n",
      "        [0.9630]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 60, Train Loss: 0.10260841250419617, Test Loss: 0.13600505888462067\n",
      "tensor([[0.0502],\n",
      "        [0.9078],\n",
      "        [0.9775],\n",
      "        [0.0673],\n",
      "        [0.8542],\n",
      "        [0.7251],\n",
      "        [0.0490],\n",
      "        [0.9638]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 61, Train Loss: 0.10087236016988754, Test Loss: 0.13353568315505981\n",
      "tensor([[0.0492],\n",
      "        [0.9097],\n",
      "        [0.9778],\n",
      "        [0.0667],\n",
      "        [0.8561],\n",
      "        [0.7290],\n",
      "        [0.0482],\n",
      "        [0.9645]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 62, Train Loss: 0.09919735044240952, Test Loss: 0.13115550577640533\n",
      "tensor([[0.0483],\n",
      "        [0.9116],\n",
      "        [0.9781],\n",
      "        [0.0661],\n",
      "        [0.8579],\n",
      "        [0.7328],\n",
      "        [0.0474],\n",
      "        [0.9652]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 63, Train Loss: 0.09758031368255615, Test Loss: 0.12885984778404236\n",
      "tensor([[0.0474],\n",
      "        [0.9135],\n",
      "        [0.9785],\n",
      "        [0.0655],\n",
      "        [0.8597],\n",
      "        [0.7364],\n",
      "        [0.0466],\n",
      "        [0.9659]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 64, Train Loss: 0.09601835161447525, Test Loss: 0.12664462625980377\n",
      "tensor([[0.0466],\n",
      "        [0.9152],\n",
      "        [0.9788],\n",
      "        [0.0650],\n",
      "        [0.8615],\n",
      "        [0.7400],\n",
      "        [0.0459],\n",
      "        [0.9666]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 65, Train Loss: 0.09450873732566833, Test Loss: 0.1245056763291359\n",
      "tensor([[0.0458],\n",
      "        [0.9169],\n",
      "        [0.9791],\n",
      "        [0.0645],\n",
      "        [0.8631],\n",
      "        [0.7435],\n",
      "        [0.0452],\n",
      "        [0.9672]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 66, Train Loss: 0.09304893761873245, Test Loss: 0.12243915349245071\n",
      "tensor([[0.0450],\n",
      "        [0.9186],\n",
      "        [0.9794],\n",
      "        [0.0639],\n",
      "        [0.8648],\n",
      "        [0.7470],\n",
      "        [0.0445],\n",
      "        [0.9679]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 67, Train Loss: 0.09163648635149002, Test Loss: 0.12044157087802887\n",
      "tensor([[0.0442],\n",
      "        [0.9202],\n",
      "        [0.9797],\n",
      "        [0.0634],\n",
      "        [0.8664],\n",
      "        [0.7503],\n",
      "        [0.0438],\n",
      "        [0.9684]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 68, Train Loss: 0.09026918560266495, Test Loss: 0.11850965023040771\n",
      "tensor([[0.0435],\n",
      "        [0.9217],\n",
      "        [0.9799],\n",
      "        [0.0629],\n",
      "        [0.8679],\n",
      "        [0.7535],\n",
      "        [0.0432],\n",
      "        [0.9690]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 69, Train Loss: 0.08894486725330353, Test Loss: 0.11664009094238281\n",
      "tensor([[0.0427],\n",
      "        [0.9232],\n",
      "        [0.9802],\n",
      "        [0.0625],\n",
      "        [0.8694],\n",
      "        [0.7567],\n",
      "        [0.0426],\n",
      "        [0.9696]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 70, Train Loss: 0.08766157180070877, Test Loss: 0.11483000963926315\n",
      "tensor([[0.0420],\n",
      "        [0.9246],\n",
      "        [0.9804],\n",
      "        [0.0620],\n",
      "        [0.8709],\n",
      "        [0.7597],\n",
      "        [0.0420],\n",
      "        [0.9701]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 71, Train Loss: 0.08641734719276428, Test Loss: 0.11307668685913086\n",
      "tensor([[0.0414],\n",
      "        [0.9260],\n",
      "        [0.9807],\n",
      "        [0.0615],\n",
      "        [0.8723],\n",
      "        [0.7628],\n",
      "        [0.0414],\n",
      "        [0.9706]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 72, Train Loss: 0.08521046489477158, Test Loss: 0.11137746274471283\n",
      "tensor([[0.0407],\n",
      "        [0.9273],\n",
      "        [0.9809],\n",
      "        [0.0611],\n",
      "        [0.8737],\n",
      "        [0.7657],\n",
      "        [0.0408],\n",
      "        [0.9711]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 73, Train Loss: 0.08403922617435455, Test Loss: 0.10972987860441208\n",
      "tensor([[0.0401],\n",
      "        [0.9286],\n",
      "        [0.9812],\n",
      "        [0.0607],\n",
      "        [0.8751],\n",
      "        [0.7685],\n",
      "        [0.0403],\n",
      "        [0.9716]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 74, Train Loss: 0.08290208876132965, Test Loss: 0.10813160240650177\n",
      "tensor([[0.0395],\n",
      "        [0.9298],\n",
      "        [0.9814],\n",
      "        [0.0602],\n",
      "        [0.8764],\n",
      "        [0.7713],\n",
      "        [0.0397],\n",
      "        [0.9721]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 75, Train Loss: 0.0817975103855133, Test Loss: 0.10658049583435059\n",
      "tensor([[0.0389],\n",
      "        [0.9311],\n",
      "        [0.9816],\n",
      "        [0.0598],\n",
      "        [0.8777],\n",
      "        [0.7740],\n",
      "        [0.0392],\n",
      "        [0.9725]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 76, Train Loss: 0.08072411268949509, Test Loss: 0.10507441312074661\n",
      "tensor([[0.0383],\n",
      "        [0.9322],\n",
      "        [0.9818],\n",
      "        [0.0594],\n",
      "        [0.8789],\n",
      "        [0.7767],\n",
      "        [0.0387],\n",
      "        [0.9730]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 77, Train Loss: 0.07968059927225113, Test Loss: 0.10361148416996002\n",
      "tensor([[0.0378],\n",
      "        [0.9334],\n",
      "        [0.9821],\n",
      "        [0.0590],\n",
      "        [0.8802],\n",
      "        [0.7793],\n",
      "        [0.0382],\n",
      "        [0.9734]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 78, Train Loss: 0.07866561412811279, Test Loss: 0.10218977928161621\n",
      "tensor([[0.0372],\n",
      "        [0.9345],\n",
      "        [0.9823],\n",
      "        [0.0586],\n",
      "        [0.8814],\n",
      "        [0.7818],\n",
      "        [0.0377],\n",
      "        [0.9738]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 79, Train Loss: 0.07767805457115173, Test Loss: 0.10080763697624207\n",
      "tensor([[0.0367],\n",
      "        [0.9355],\n",
      "        [0.9825],\n",
      "        [0.0582],\n",
      "        [0.8825],\n",
      "        [0.7843],\n",
      "        [0.0373],\n",
      "        [0.9742]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 80, Train Loss: 0.07671676576137543, Test Loss: 0.09946342557668686\n",
      "tensor([[0.0362],\n",
      "        [0.9366],\n",
      "        [0.9827],\n",
      "        [0.0579],\n",
      "        [0.8837],\n",
      "        [0.7867],\n",
      "        [0.0368],\n",
      "        [0.9746]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 81, Train Loss: 0.07578069716691971, Test Loss: 0.09815554320812225\n",
      "tensor([[0.0357],\n",
      "        [0.9376],\n",
      "        [0.9828],\n",
      "        [0.0575],\n",
      "        [0.8848],\n",
      "        [0.7891],\n",
      "        [0.0364],\n",
      "        [0.9750]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 82, Train Loss: 0.0748688280582428, Test Loss: 0.09688250720500946\n",
      "tensor([[0.0352],\n",
      "        [0.9386],\n",
      "        [0.9830],\n",
      "        [0.0571],\n",
      "        [0.8859],\n",
      "        [0.7914],\n",
      "        [0.0359],\n",
      "        [0.9753]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 83, Train Loss: 0.07398021966218948, Test Loss: 0.09564293920993805\n",
      "tensor([[0.0347],\n",
      "        [0.9395],\n",
      "        [0.9832],\n",
      "        [0.0568],\n",
      "        [0.8870],\n",
      "        [0.7937],\n",
      "        [0.0355],\n",
      "        [0.9757]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 84, Train Loss: 0.07311391085386276, Test Loss: 0.09443555772304535\n",
      "tensor([[0.0343],\n",
      "        [0.9404],\n",
      "        [0.9834],\n",
      "        [0.0564],\n",
      "        [0.8880],\n",
      "        [0.7959],\n",
      "        [0.0351],\n",
      "        [0.9760]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 85, Train Loss: 0.07226911187171936, Test Loss: 0.09325903654098511\n",
      "tensor([[0.0338],\n",
      "        [0.9413],\n",
      "        [0.9836],\n",
      "        [0.0561],\n",
      "        [0.8891],\n",
      "        [0.7980],\n",
      "        [0.0347],\n",
      "        [0.9764]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 86, Train Loss: 0.07144495844841003, Test Loss: 0.09211225807666779\n",
      "tensor([[0.0334],\n",
      "        [0.9422],\n",
      "        [0.9837],\n",
      "        [0.0558],\n",
      "        [0.8901],\n",
      "        [0.8002],\n",
      "        [0.0343],\n",
      "        [0.9767]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 87, Train Loss: 0.07064072787761688, Test Loss: 0.09099399298429489\n",
      "tensor([[0.0330],\n",
      "        [0.9431],\n",
      "        [0.9839],\n",
      "        [0.0554],\n",
      "        [0.8911],\n",
      "        [0.8022],\n",
      "        [0.0339],\n",
      "        [0.9770]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 88, Train Loss: 0.06985559314489365, Test Loss: 0.08990328013896942\n",
      "tensor([[0.0325],\n",
      "        [0.9439],\n",
      "        [0.9841],\n",
      "        [0.0551],\n",
      "        [0.8920],\n",
      "        [0.8043],\n",
      "        [0.0335],\n",
      "        [0.9773]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 89, Train Loss: 0.06908892095088959, Test Loss: 0.08883904665708542\n",
      "tensor([[0.0321],\n",
      "        [0.9447],\n",
      "        [0.9842],\n",
      "        [0.0548],\n",
      "        [0.8930],\n",
      "        [0.8063],\n",
      "        [0.0332],\n",
      "        [0.9776]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 90, Train Loss: 0.06834001839160919, Test Loss: 0.0878002867102623\n",
      "tensor([[0.0317],\n",
      "        [0.9455],\n",
      "        [0.9844],\n",
      "        [0.0545],\n",
      "        [0.8939],\n",
      "        [0.8082],\n",
      "        [0.0328],\n",
      "        [0.9779]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 91, Train Loss: 0.0676082968711853, Test Loss: 0.08678615838289261\n",
      "tensor([[0.0314],\n",
      "        [0.9462],\n",
      "        [0.9845],\n",
      "        [0.0542],\n",
      "        [0.8948],\n",
      "        [0.8101],\n",
      "        [0.0325],\n",
      "        [0.9782]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 92, Train Loss: 0.06689310073852539, Test Loss: 0.08579568564891815\n",
      "tensor([[0.0310],\n",
      "        [0.9470],\n",
      "        [0.9847],\n",
      "        [0.0539],\n",
      "        [0.8957],\n",
      "        [0.8120],\n",
      "        [0.0321],\n",
      "        [0.9785]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 93, Train Loss: 0.06619388610124588, Test Loss: 0.08482813090085983\n",
      "tensor([[0.0306],\n",
      "        [0.9477],\n",
      "        [0.9848],\n",
      "        [0.0536],\n",
      "        [0.8966],\n",
      "        [0.8138],\n",
      "        [0.0318],\n",
      "        [0.9788]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 94, Train Loss: 0.06551006436347961, Test Loss: 0.08388262987136841\n",
      "tensor([[0.0303],\n",
      "        [0.9484],\n",
      "        [0.9850],\n",
      "        [0.0533],\n",
      "        [0.8974],\n",
      "        [0.8156],\n",
      "        [0.0315],\n",
      "        [0.9790]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 95, Train Loss: 0.0648411437869072, Test Loss: 0.08295842260122299\n",
      "tensor([[0.0299],\n",
      "        [0.9491],\n",
      "        [0.9851],\n",
      "        [0.0530],\n",
      "        [0.8983],\n",
      "        [0.8174],\n",
      "        [0.0311],\n",
      "        [0.9793]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 96, Train Loss: 0.06418662518262863, Test Loss: 0.08205482363700867\n",
      "tensor([[0.0296],\n",
      "        [0.9498],\n",
      "        [0.9852],\n",
      "        [0.0527],\n",
      "        [0.8991],\n",
      "        [0.8191],\n",
      "        [0.0308],\n",
      "        [0.9796]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 97, Train Loss: 0.06354602426290512, Test Loss: 0.08117106556892395\n",
      "tensor([[0.0292],\n",
      "        [0.9504],\n",
      "        [0.9854],\n",
      "        [0.0524],\n",
      "        [0.8999],\n",
      "        [0.8208],\n",
      "        [0.0305],\n",
      "        [0.9798]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 98, Train Loss: 0.06291888654232025, Test Loss: 0.08030657470226288\n",
      "tensor([[0.0289],\n",
      "        [0.9511],\n",
      "        [0.9855],\n",
      "        [0.0522],\n",
      "        [0.9007],\n",
      "        [0.8225],\n",
      "        [0.0302],\n",
      "        [0.9801]], grad_fn=<SigmoidBackward0>) torch.Size([8, 1]) torch.Size([2, 1])\n",
      "Epoch: 99, Train Loss: 0.06230471283197403, Test Loss: 0.07946068048477173\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "epochs  = 100\n",
    "epoch_set = []\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    y_preds = model(X_train)\n",
    "  \n",
    "    print(y_preds , y_preds.shape , y_test.shape)\n",
    "    loss1 = loss(y_preds,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss1.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    epoch_set.append(epoch)\n",
    "    train_loss.append(loss1.item())\n",
    "    with torch.inference_mode():\n",
    "        y_preds_test = model(X_test)\n",
    "        loss2 = loss(y_preds_test,y_test)\n",
    "        test_loss.append(loss2.item())\n",
    "    print(\"Epoch: {}, Train Loss: {}, Test Loss: {}\".format(epoch,loss1.item(),loss2.item()))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_epoch_loss(epoch,loss,color):\n",
    "    plt.plot(epoch,loss,color)\n",
    "plot_epoch_loss(epoch_set,test_loss,color = \"g--\")\n",
    "plot_epoch_loss(epoch_set,train_loss,color = \"r--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_p = model(X_test)\n",
    "    ll = loss(y_p,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"models/classifier_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature 2')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAFzCAYAAADWqstZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAbkElEQVR4nO3de7BedX3v8feHgAgBsTaBIBLAllaxp7aeXQoH64CIcrOpFjCejlB7SQWx9o9eOLVjz3ROWzi1p1MFtchhhI6CNxAoN5WpoM5B2FCQmygCSoQxeCOBhJCQ7/njebDbZO+dJ8l+nrX3b79fM8/stX7rt9f6rllP8tnrnqpCkiS1aaeuC5AkScNj0EuS1DCDXpKkhhn0kiQ1zKCXJKlhBr0kSQ3buesChmHRokV14IEHdl2GJEkjcdttt32/qhZPNq3JoD/wwAMZHx/vugxJkkYiybenmuahe0mSGmbQS5LUMINekqSGGfSSJDXMoJckqWEGvSRJDTPoJUlqmEEvSVLDDHpJkhpm0EuSNAobNsCdd8JDD410sQa9JEnD9pnPwD77wG/8BrziFTA2BitXjmTRBr0kScN0111w6qnwox/BmjWwbh3ccQcccwxUDX3xBr0kScN07rmwfv1Ptz37bG+P/pZbhr54g16SpGF65JFesG9up53ge98b+uINekmShunYY2H33bdsX78eDj106Is36CVJGqbf+z1YsgR23fU/2xYuhD/+4177kO089CVIkjSf7bEH3HYb/NM/wWWXwV57wbvfDSedNJLFp0Zwxd+ojY2N1fj4eNdlSJI0Ekluq6qxyaZ56F6SpIYZ9JIkNcyglySpYQa9JEkNM+glSWqYQS9JUsMMekmSGmbQS5LUsE6DPsmFSVYluXuK6UcmeSLJHf3Pe0ddoyRJc1nXj8D9KHAucPE0fb5UVSeOphxJktrS6R59Vd0E/LDLGiRJatlcOEd/eJI7k1yb5BVTdUqyIsl4kvHHH398lPVJkjRrzfagvx04oKpeCXwA+OxUHavq/Koaq6qxxYsXj6xASZJms1kd9FW1uqqe7A9fA+ySZFHHZUmSNGfM6qBPsiRJ+sOH0qv3B91WJUnS3NHpVfdJLgGOBBYlWQn8NbALQFV9GDgJOD3JRmAdsLyqqqNyJUmaczoN+qp661amn0vv9jtJkrQdZvWhe0mStGMMekmSGmbQS5LUMINekqSGGfSSJDXMoJckqWEGvSRJDTPoJUlqmEEvSVLDDHpJkhpm0EuS1DCDXpKkhhn0kiQ1zKCXJKlhBr0kSQ0z6CVJaphBL0lSwwx6SZIaZtBLktQwg16SpIYZ9JIkNcyglySpYQa9JEkNM+glSWqYQS9JUsMMekmSGmbQS5LUMINekqSGGfSSJDXMoJckqWEGvSRJDTPoJUlqmEEvSVLDDHpJkhpm0EuS1DCDXpKkhnUa9EkuTLIqyd1TTE+S9yd5IMnXkrxq1DVKkjSXdb1H/1Hg2GmmHwcc3P+sAD40gpokSWpGp0FfVTcBP5ymyzLg4uq5GXhhkn1HU50kSXNf13v0W7Mf8MiE8ZX9ti0kWZFkPMn4448/PpLiJEma7WZ70GeStpqsY1WdX1VjVTW2ePHiIZclSdLcMNuDfiWw/4TxlwCPdlSLJElzzmwP+iuBU/tX3x8GPFFVj3VdlCRJc8XOXS48ySXAkcCiJCuBvwZ2AaiqDwPXAMcDDwBrgbd3U6kkSXNTp0FfVW/dyvQC3jmiciRJas5sP3QvSZJ2gEEvSVLDDHpJkhrW6Tl67Zjbb4fPfQ723BNOOQV8fIAkaXMG/RxUBStWwMc/Ds88A7vsAn/+5/DpT8Nxx3VdnSRpNvHQ/Rx07bVwySWwdi1s3Ajr1vWGTzmlNyxJ0nMM+jnooovgqae2bN9pJ/jiF0dejiRpFjPoG1OTvglAkjRfGfRz0NveBgsXbtm+aRMcddTo65EkzV4G/Rx0wgm98/G77w4LFsBuu/WGL720NyxJ0nO86n4OSuDCC+GMM+D66+EFL+gF/z77dF2ZJGm2MejnsLGx3keSpKl46F6SpIYZ9JIkNcyglySpYQa9JEkNM+glSWqYQS9JUsMMekmSGmbQS5LUMINekqSGGfSSJDXMoJckqWEGvSRJDTPoJUlqmEEvSVLDDHpJkhpm0EuS1DCDfhr33AMnnAB77QUvfSmcey5UdV2VJEmD27nrAmarBx+Eww+HJ5/shfvq1fAXfwEPPwzve1/X1UmSNBj36Kdw9tmwbt1P78GvXQvnnQc//nF3dUmStC0M+incfDNs3Lhl+667wje+Mfp6JEnaHgb9FF72Mki2bF+/HpYuHX09kiRtD4N+CmedBbvt9tNtz38+/OZvwpIl3dQkSdK2Muin8KpXwWWXwUEHwS679EL+1FPhoou6rkySpMF1etV9kmOBfwYWABdU1dmbTT8SuAJ4qN90WVX9zajqe8Mb4Fvf6l1xv/vuvcCXJGku6SzokywAzgOOAVYCtya5sqru3azrl6rqxJEX2Jf07qOXJGku6vLQ/aHAA1X1YFU9A1wKLOuwHkmSmtNl0O8HPDJhfGW/bXOHJ7kzybVJXjGa0iRJakOX5+gnuXmNzR8weztwQFU9meR44LPAwZPOLFkBrABY6v1vkiQB3e7RrwT2nzD+EuDRiR2qanVVPdkfvgbYJcmiyWZWVedX1VhVjS1evHhYNUuSNKd0GfS3AgcnOSjJ84DlwJUTOyRZkvQeW5PkUHr1/mDklUqSNEd1dui+qjYmORO4nt7tdRdW1T1J3tGf/mHgJOD0JBuBdcDyKt8fJ0nSoNJibo6NjdX4+HjXZUiSNBJJbquqscmm+WQ8SZIaZtBLktQwg16SpIYZ9JIkNcyglySpYQa9JEkNM+glSWqYQS9JUsO6fKmNpLlk0ya46SZYtQqOOAL2m+xlk5JmG4Ne0tY98AAcfTT86Ee98Q0b4F3vgnPOgUz2IkpJs4WH7iVNrwpOPBEeeQTWrOl9nn4aPvhBuOKKrquTtBUGvaTp3XsvrFzZC/yJnnoKzjuvm5okDcyglzS9NWtgwYLJpz3xxGhrkbTNDHpJ0/vVX528fbfd4C1vGW0tkraZQS9pervuChdc0Av25/bsFy6En/95eMc7uq1N0lZNGfRJ/kuSm5M8kuT8JD8zYdotoylP0qxw8skwPg5nnAFvfjN84ANwyy29wJc0q013e92HgP8J3Az8AfDlJL9ZVd8CdhlBbZJmk0MOgfe/v+sqJG2j6YJ+j6q6rj/8viS3AdcleRtQ0/yeJEmaJaYL+iTZq6qeAKiqf0/y28BngBeNpDpJkrRDprsY7xzg5RMbquprwNHAZcMsSpIkzYwp9+ir6uNTtH8H+MOhVSRJkmaMt9dJktQwg16SpIYZ9JIkNWyrQZ/kF5LckOTu/vgvJ/mr4ZcmSZJ21CB79B8B/gewAX5y5f3yYRYlSZJmxiBBv3tVbf7I243DKEaSJM2sQYL++0l+jv7T8JKcBDw21KokSdKMmO7JeM95J3A+8LIk3wUeAn5nqFVJkqQZMW3QJ9kJGKuq1yVZCOxUVWtGU5okSdpR0x66r6pNwJn94acMeUmS5pZBztF/PsmfJtk/yYue+wy9MkmStMMGOUf/e/2f75zQVsBLZ74cSZI0k7Ya9FV10CgKkSRJM2+rQZ/k1Mnaq+rimS9HkiTNpEEO3f/ahOHn03sf/e2AQS9J0iw3yKH7d00cT7IX8K8zsfAkxwL/DCwALqiqszebnv7044G1wO9W1e0zsWxJkuaD7Xl73Vrg4B1dcJIFwHnAccAhwFuTHLJZt+P6yzoYWAF8aEeXK0nSfDLIOfqr6D/+lt4fBocAn5qBZR8KPFBVD/aXcymwDLh3Qp9lwMVVVcDNSV6YZN+q8hG8kiQNYJBz9O+bMLwR+HZVrZyBZe8HPDJhfCXw6wP02Q+ftS9J0kAGOXR/fFXd2P98papWJjlnBpadSdpqO/r0OiYrkownGX/88cd3uDhJklowSNAfM0nbcTOw7JXA/hPGXwI8uh19AKiq86tqrKrGFi9ePAPlSZI0900Z9ElOT3IX8ItJvjbh8xDwtRlY9q3AwUkOSvI8YDlw5WZ9rgROTc9hwBOen5ckaXDTnaP/OHAt8PfAWRPa11TVD3d0wVW1McmZwPX0bq+7sKruSfKO/vQPA9fQu7XuAXpX+799R5crSdJ8kt4F7QN0TPam98AcAKrqO8MqakeNjY3V+Ph412VIkjQSSW6rqrHJpm31HH2SNyb5JvAQcCPwML09fUmSNMsNcjHe/wIOA77Rf8HN0cBXhlqVJEmaEYME/Yaq+gGwU5KdqurfgV8Zcl2SJGkGDPLAnB8n2QP4EvCxJKvoPThHkiTNcoPs0S+jd8X7nwDXAd8C3jjMoiRJ0swY5O11TyU5ADi4qi5Ksju92+EkSdIsN8hV938IfBr4l37TfsBnh1mUJEmaGYMcun8ncASwGqCqvgnsPcyiJEnSzBgk6NdX1TPPjSTZmSleLCNJkmaXQYL+xiR/CeyW5Bh676K/arhlSZKkmTBI0J8FPA7cBfwRvefP/9Uwi5IkSTNjyqvukyytqu9U1SbgI/2PJEmaQ6bbo//JlfVJPjOCWiRptFatgttvhzVruq5EGprpgj4Thl867EIkaWTWrYNTToGlS+Goo2CffeC974UB3+YpzSXTBX1NMSxJc9uZZ8JVV8H69bB6dS/4//Ef4aMf7boyacZNF/SvTLI6yRrgl/vDq5OsSbJ6VAVK0oxatw4+9jF4+umfbl+7Fs45p5uapCGa8mK8qvIxt5LaM935+McfH10d0ogMcnudJLVj8WJYtGjL9gRe85rR1yMNmUEvaX5J4LzzYPfde8MACxbAHnvA3/1dt7VJQ2DQS5p/li2DG26AN74RXv5yOO00+I//6A1Ljdnqa2olqUmHHQZXXNF1FdLQuUcvSVLDDHpJkhpm0EuS1DCDXpKkhhn0kiQ1zKCXJKlhBr0kSQ0z6CVJaphBL0lSwwx6SZIaZtBLktQwg16SpIYZ9JIkNcyglySpYQa9JEkN6+R99EleBHwCOBB4GDilqn40Sb+HgTXAs8DGqhobXZWSJM19Xe3RnwXcUFUHAzf0x6dyVFX9ylwJ+fXr4eKL4S1vgXe/G+69t+uKJEnzWSd79MAy4Mj+8EXAF4G/6KiWGbNuHbz61XD//fDUU7BgAXzkI/DRj8Ipp3RdnSRpPupqj36fqnoMoP9z7yn6FfC5JLclWTGy6rbTBRfA17/eC3mAZ5/thf8f/EFvT1+SpFEb2h59ki8ASyaZ9J5tmM0RVfVokr2Bzyf5elXdNMXyVgArAJYuXbrN9c6ESy+FtWu3bE/g1lt7e/uSJI3S0IK+ql431bQk30uyb1U9lmRfYNUU83i0/3NVksuBQ4FJg76qzgfOBxgbG6sdrX97vOAFk7dv2gR77DHaWiRJgu4O3V8JnNYfPg24YvMOSRYm2fO5YeD1wN0jq3A7vPOdsHDhT7clsPfe8MpXdlOTJGl+6yrozwaOSfJN4Jj+OElenOSafp99gC8nuRO4Bbi6qq7rpNoBnXBCL+yf/3zYc8/eZ8kSuPrqXuBLkjRqqerkKPdQjY2N1fj4eGfL/+534UtfgkWL4KijelffS5I0LElum+o29K5ur2vafvvB8uVdVyFJko/AlSSpaQa9JEkNM+glSWqYQS9JUsMMekmSGmbQS5LUMINekqSGGfSSJDXMoJckqWEGvSRJDTPoJUlqmEEvSVLDDHpJkhpm0EuS1DCDXpKkhhn0kiQ1zKCXJKlhBr0kSQ0z6CVJaphBL0lSwwx6SZIaZtBLktQwg16SpIYZ9JIkNcyglySpYQa9JEkNM+glSWqYQS9JUsMMekmSGmbQS5LUMINekqSGGfSSJDXMoJckqWEGvSRJDTPoJUlqWCdBn+TkJPck2ZRkbJp+xya5P8kDSc4aZY2SJLWgqz36u4E3AzdN1SHJAuA84DjgEOCtSQ4ZTXmSJLVh5y4WWlX3ASSZrtuhwANV9WC/76XAMuDeoRcoSVIjZvM5+v2ARyaMr+y3SZKkAQ1tjz7JF4Alk0x6T1VdMcgsJmmraZa3AlgBsHTp0oFqlCSpdUML+qp63Q7OYiWw/4TxlwCPTrO884HzAcbGxqb8g0AS8MMfwqc+1fv52tfCoYfC9KfSJM1RnZyjH9CtwMFJDgK+CywH/nu3JUkNuPFGOPFE2LQJ1q+Hv/1bOOEEuOQS2Gk2n82TtD26ur3uTUlWAocDVye5vt/+4iTXAFTVRuBM4HrgPuCTVXVPF/VKzdi4EX77t+HJJ2HtWnj2WXjqKbj6avjkJ7uuTtIQdHXV/eXA5ZO0PwocP2H8GuCaEZYmte2rX4UNG7Zsf+opuPBCWL589DVJGiqP00nzSXn5ijTfGPTSfHLYYbDzJAfyFi6Et7999PVIGjqDXppPdt4ZPv3pXrDvtlvv4ruFC+ENb4C3vKXr6iQNwWy+6l7SMBx1FHz72/CJT/Rurzv66N6evrfXSU0y6KX56Gd/Fs44o+sqJI2Ah+4lSWqYQS9JUsMMekmSGmbQS5LUMINekqSGGfSSJDXMoJckqWEGvSRJDTPoJUlqmEEvSVLDDHpJkhpm0EuS1DCDXpKkhhn0kiQ1zKCXJKlhBr0kSQ0z6CVJaphBL0lSwwx6SZIaZtBLktQwg16SpIYZ9JIkNcyglySpYQa9JEkNM+glSWqYQS9JUsMMekmSGmbQS5LUMINekqSGGfSSJDXMoJckqWGdBH2Sk5Pck2RTkrFp+j2c5K4kdyQZH2WNkiS1YOeOlns38GbgXwboe1RVfX/I9UiS1KROgr6q7gNI0sXiJUmaN2b7OfoCPpfktiQrui5GkqS5Zmh79Em+ACyZZNJ7quqKAWdzRFU9mmRv4PNJvl5VN02xvBXACoClS5duV82SJLVmaEFfVa+bgXk82v+5KsnlwKHApEFfVecD5wOMjY3Vji5bkqQWzNpD90kWJtnzuWHg9fQu4pMkSQPq6va6NyVZCRwOXJ3k+n77i5Nc0++2D/DlJHcCtwBXV9V1XdQrSdJc1dVV95cDl0/S/ihwfH/4QeCVIy5NkqSmdHUfvTS3PP003HADPPMMvPa1sNdeXVckSQMx6KWtufFGWLYMqn+N54YN8KEPwWmndVuXJA1g1l6MJ80KTz4JJ54ITzwBq1f3PuvWwemnw/33d12dJG2VQS9N56qrYLInOG7YAP/6r6OvR5K2kUEvTefJJ+HZZ7ds37gRfvzj0dcjSdvIoJem8/rXw6ZNW7bvsQf81m+Nvh5J2kYGvTSdAw6AP/sz2H33/zyEv3Bh7w+Ao4/utjZJGoBX3Utb8zd/0wv2Cy/sXYi3fDm88Y2Tn7uXpFnGoJcG8epX9z6SNMd46F6SpIYZ9JIkNcyglySpYQa9JEkNM+glSWqYQS9JUsMMekmSGmbQS5LUMINekqSGGfSSJDXMoJckqWGpqq5rmHFJHge+3XUd22AR8P2ui+iQ6+/6u/7zl+s/M+t/QFUtnmxCk0E/1yQZr6qxruvoiuvv+rv+rn/XdXRlFOvvoXtJkhpm0EuS1DCDfnY4v+sCOub6z2+u//zm+g+Z5+glSWqYe/SSJDXMoO9AkpOT3JNkU5Ipr7ZMcmyS+5M8kOSsUdY4TElelOTzSb7Z//kzU/R7OMldSe5IMj7qOmfa1rZnet7fn/61JK/qos5hGWD9j0zyRH9735HkvV3UOQxJLkyyKsndU0xvfdtvbf2b3fYASfZP8u9J7uv/3//uSfoM7ztQVX5G/AFeDvwi8EVgbIo+C4BvAS8FngfcCRzSde0ztP7/GzirP3wWcM4U/R4GFnVd7wyt81a3J3A8cC0Q4DDgq13XPeL1PxL4t65rHdL6vwZ4FXD3FNOb3fYDrn+z276/fvsCr+oP7wl8Y5T//t2j70BV3VdV92+l26HAA1X1YFU9A1wKLBt+dSOxDLioP3wR8Fsd1jIqg2zPZcDF1XMz8MIk+4660CFp+fu8VVV1E/DDabq0vO0HWf+mVdVjVXV7f3gNcB+w32bdhvYdMOhnr/2ARyaMr2TLL8ZctU9VPQa9fwDA3lP0K+BzSW5LsmJk1Q3HINuz5W0+6LodnuTOJNcmecVoSpsVWt72g5oX2z7JgcCvAl/dbNLQvgM7z8RMtKUkXwCWTDLpPVV1xSCzmKRtztwiMd36b8NsjqiqR5PsDXw+ydf7ewZz0SDbc05v860YZN1up/cYzyeTHA98Fjh46JXNDi1v+0HMi22fZA/gM8CfVNXqzSdP8isz8h0w6Iekql63g7NYCew/YfwlwKM7OM+RmW79k3wvyb5V9Vj/0NSqKebxaP/nqiSX0zv8O1eDfpDtOae3+VZsdd0m/sdXVdck+WCSRVU1H56D3vK236r5sO2T7EIv5D9WVZdN0mVo3wEP3c9etwIHJzkoyfOA5cCVHdc0U64ETusPnwZscYQjycIkez43DLwemPSK3TlikO15JXBq/+rbw4AnnjvF0YCtrn+SJUnSHz6U3v9PPxh5pd1oedtvVevbvr9u/xe4r6r+zxTdhvYdcI++A0neBHwAWAxcneSOqnpDkhcDF1TV8VW1McmZwPX0rli+sKru6bDsmXQ28Mkkvw98BzgZYOL6A/sAl/f/7e8MfLyqruuo3h021fZM8o7+9A8D19C78vYBYC3w9q7qnWkDrv9JwOlJNgLrgOXVvxx5rktyCb0ryxclWQn8NbALtL/tYaD1b3bb9x0BvA24K8kd/ba/BJbC8L8DPhlPkqSGeehekqSGGfSSJDXMoJckqWEGvSRJDTPoJUlqmEEvzTNJnp3wlrA7+o/k3NZ5vDDJGTNf3U/m/7Ik/y/J+iR/OqzlSPOBt9dJ80ySJ6tqjx2cx4H03jb2S9v4ewuq6tkB+u0NHEDvhUc/qqr3bU+dktyjl0QvgJP8Q5Jb++/C/qN++x5Jbkhye5K7kjz3xrmzgZ/rHxH4h/77xP9twvzOTfK7/eGHk7w3yZeBk5P8XJLr+i8r+lKSl21eT1WtqqpbgQ1DX3mpcT4ZT5p/dpvwdK6HqupNwO/Te+TmryXZFfhKks/Re5vWm6pqdZJFwM1JrgTOAn6pqn4FIMmRW1nm01X16n7fG4B3VNU3k/w68EHgtTO9kpJ6DHpp/ln3XEBP8Hrgl5Oc1B/fi97bw1YCf5fkNcAmeq/N3Gc7lvkJ+Mnbu/4b8Kn+440Bdt2O+UkakEEvCXqvyHxXVV3/U429w++Lgf9aVRuSPAw8f5Lf38hPnwrcvM9T/Z87AT+e5A8NSUPiOXpJ0HvZzOn9V2mS5Bf6bw3cC1jVD/mj6F0gB7AG2HPC738bOCTJrkn2Ao6ebCH915E+lOS5FxklySuHs0qSwD16ST0XAAcCt/dfqfk4vSvePwZclWQcuAP4OkBV/SDJV5LcDVxbVX+W5JPA14BvAv8xzbJ+B/hQkr+i9wazS4E7J3ZIsgQYB14AbEryJ8AhE99bLmkw3l4nSVLDPHQvSVLDDHpJkhpm0EuS1DCDXpKkhhn0kiQ1zKCXJKlhBr0kSQ0z6CVJatj/B3z8XCrfaJiFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train.squeeze(), cmap='bwr', label='True Labels')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
