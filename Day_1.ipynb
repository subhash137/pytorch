{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor_data = torch.tensor([1,2,3])  # tensor is a numerical representation\n",
    "print(tensor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tensor_data = torch.tensor([1,2,3],dtype=torch.float64)  # requires_grad=False , pin_memory=False  , device=torch.device('cuda:0') or device = \"cuda\" or \"cpu\"\n",
    "print(tensor_data)\n",
    "\n",
    "#Arrays can have varying dimensions, but don't inherently represent scalars, vectors, or matrices\t\n",
    "# Tensors encompass scalars, vectors, and matrices as special cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  tensor_data.item()  # only for scalar data\n",
    "tensor_data.shape  # (3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "torch.Size([1, 3, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "t3D_tensor = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "\n",
    "print(t3D_tensor)\n",
    "\n",
    "print(t3D_tensor.shape)\n",
    "\n",
    "\n",
    "print(t3D_tensor.ndim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PIN MEMORY  ---- \n",
    " \n",
    " the pin_memory parameter is typically used in the data loading process when working with DataLoader objects. When pin_memory is set to True, it enables the data to be directly transferred to the GPU memory (if available) from the host memory (RAM) during the data loading process. This can potentially speed up the data transfer between CPU and GPU, leading to faster training times.\n",
    "\n",
    "However, when pin_memory is set to True, it also consumes additional CPU memory, as it creates a pinned memory buffer to facilitate the data transfer. This may not be an issue if the system has sufficient RAM to spare.\n",
    "\n",
    "If you set pin_memory to False, it means that the data will not be directly transferred to the GPU memory during data loading. Instead, it will stay in the host memory (RAM) and will be transferred to the GPU on-the-fly during the training process. This could result in slightly slower data transfer times between CPU and GPU, but it reduces the additional memory overhead on the CPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTOGRAD   --- \n",
    "\n",
    "Instead, autograd is a fundamental feature of PyTorch that is always enabled by default. It is responsible for automatic differentiation, which is a key component of training neural networks through backpropagation.\n",
    "\n",
    "Automatic differentiation is a technique that allows the framework to automatically compute gradients of the loss function with respect to all the learnable parameters in the model. Gradients represent the direction and magnitude of the steepest increase of the loss function with respect to each parameter, which is used to update the parameters during training and minimize the loss.\n",
    "\n",
    "When autograd is set to True, PyTorch keeps track of all the operations performed on tensors (inputs, activations, etc.) that are involved in calculating the loss. This creates a computational graph, which is used to compute the gradients when you call the backward() method on the loss tensor. This process propagates the gradients backward through the network and computes the gradients for each parameter.\n",
    "\n",
    "In summary, autograd=True is the default behavior in PyTorch, and it is crucial for enabling automatic differentiation, which is essential for training deep learning models using gradient-based optimization techniques like stochastic gradient descent (SGD) or Adam.\n",
    "\n",
    "You can think of autograd as the engine that powers the automatic computation of gradients, making it easier for developers to define and train complex neural network architectures without having to derive and implement gradients manually for each parameter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUMEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 4])\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,2,3,4)\n",
    "print(a.shape)\n",
    "numel_data = torch.numel(a)  # calculates total number of elements in the data matrix\n",
    "print(numel_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4626, 0.7164, 0.7406, 0.6282, 0.9490])\n"
     ]
    }
   ],
   "source": [
    "random_tensors = torch.rand(5)\n",
    "print(random_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1778, 0.7985, 0.3029, 0.1362],\n",
      "        [0.1322, 0.7722, 0.2843, 0.1168],\n",
      "        [0.4158, 0.8765, 0.5435, 0.0484]])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "r2 = torch.rand(3,4)\n",
    "print(r2)\n",
    "print(r2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "r3 = torch.rand(3,224,224) # image type\n",
    "print(r3.ndim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization in Neural Networks: \n",
    "\n",
    "In deep learning, random tensors are often used for weight initialization in neural networks. Proper initialization can significantly impact the training process, leading to faster convergence and better generalization. Random initialization helps avoid symmetry issues and ensures that neurons start with diverse initial weights, which can improve learning efficiency.\n",
    "\n",
    "Data Augmentation: \n",
    "\n",
    "Random tensors are employed in data augmentation techniques to increase the size and diversity of training datasets. By applying random transformations to input data (e.g., rotations, translations, flips), the model becomes more robust and better at generalizing to unseen examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "zero_tensor = torch.zeros(3,3)\n",
    "print(zero_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 7])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,8,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(input = torch.arange(1, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVERT FLOAT 32 TO FLOAT 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "float32_tensor = torch.tensor([1.0,2.0,3.0],dtype = None,device = \"cpu\",requires_grad=False)\n",
    "print(float32_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "float16_tensor = float32_tensor.type(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(float16_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision in computing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can multiply in32 with float32 result is float32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensors errors are --  (tensor attributes)\n",
    "\n",
    "1.tensor shape \n",
    "\n",
    "2.tensor device \n",
    "\n",
    "3.tensor dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  8, 12])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(torch.tensor([1,2,3]),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 6, 7])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(torch.tensor([1,2,3]),4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELEMENT WISE MULTIPLICATION\n",
    "\n",
    "MATRIX MULTIPLICATION (DOT PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  4,  9, 16])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3,4])\n",
    "print(t*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  4,  9, 16],\n",
      "        [36, 49, 64, 81]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1,2,3,4],[6,7,8,9]])\n",
    "print(t1*t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  4,  9, 16],\n",
      "        [ 6, 14, 24, 36]])\n"
     ]
    }
   ],
   "source": [
    "print(t1*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 156 µs, sys: 31 µs, total: 187 µs\n",
      "Wall time: 178 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([30, 80])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(t1,t)  # rather than for loops it is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([2, 4])\n",
      "CPU times: user 125 µs, sys: 0 ns, total: 125 µs\n",
      "Wall time: 84.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(t1.ndim)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find min and max and sum of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.max()\n",
    "    \n",
    "\n",
    "t2 = t1.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(t2)  # mean only for floats or complex types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40.)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9277)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.argmax() # find position of max element"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshaping , stacking, squeezing , unsqueezing , view , permute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping: Changing the shape (dimensions) of a tensor while keeping the total number of elements unchanged.\n",
    "\n",
    "Stacking: Combining tensors along a new dimension (axis) to create a new tensor.\n",
    "\n",
    "Squeezing: Removing dimensions with size 1 from a tensor, effectively reducing its rank.\n",
    "\n",
    "Unsqueezing: Adding dimensions with size 1 to a tensor, effectively increasing its rank.\n",
    "\n",
    "View: A method to reshape a tensor while sharing the same data. It creates a new view of the tensor without changing its memory layout.\n",
    "\n",
    "Permute: Rearranging the dimensions of a tensor by permuting its axes, allowing for different tensor manipulations without changing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1.0,10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.],\n",
       "        [9.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.8882e-01, 1.2898e-01, 4.6408e-01, 3.0542e-01],\n",
       "         [6.4682e-01, 3.4107e-01, 2.5581e-01, 7.1201e-01],\n",
       "         [2.4293e-01, 1.0380e-01, 9.2764e-01, 4.7837e-01]],\n",
       "\n",
       "        [[5.5024e-01, 8.4162e-05, 5.2151e-01, 6.6397e-03],\n",
       "         [2.2366e-01, 1.4404e-01, 2.4611e-01, 3.7169e-01],\n",
       "         [4.4611e-01, 2.7699e-01, 5.2093e-01, 3.2688e-01]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.8882e-01, 1.2898e-01, 4.6408e-01, 3.0542e-01, 6.4682e-01, 3.4107e-01,\n",
       "         2.5581e-01, 7.1201e-01, 2.4293e-01, 1.0380e-01, 9.2764e-01, 4.7837e-01],\n",
       "        [5.5024e-01, 8.4162e-05, 5.2151e-01, 6.6397e-03, 2.2366e-01, 1.4404e-01,\n",
       "         2.4611e-01, 3.7169e-01, 4.4611e-01, 2.7699e-01, 5.2093e-01, 3.2688e-01]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(2,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.8882e-01, 1.2898e-01, 4.6408e-01, 3.0542e-01, 6.4682e-01, 3.4107e-01,\n",
       "         2.5581e-01, 7.1201e-01, 2.4293e-01, 1.0380e-01, 9.2764e-01, 4.7837e-01,\n",
       "         5.5024e-01, 8.4162e-05, 5.2151e-01, 6.6397e-03, 2.2366e-01, 1.4404e-01,\n",
       "         2.4611e-01, 3.7169e-01, 4.4611e-01, 2.7699e-01, 5.2093e-01, 3.2688e-01]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(1,24)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view and reshape are same but view share same memory space with input x and z so change in z also change in x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(1,9)\n",
    "z , z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 5., 5., 5., 5., 5., 5.]]),\n",
       " tensor([5., 5., 5., 5., 5., 5., 5., 5., 5.]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:4] = 5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5., 5., 5., 5., 5., 5.],\n",
       "        [5., 5., 5., 5., 5., 5., 5., 5., 5.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x,x],dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5.],\n",
       "        [5., 5.],\n",
       "        [5., 5.],\n",
       "        [5., 5.],\n",
       "        [5., 5.],\n",
       "        [5., 5.],\n",
       "        [5., 5.],\n",
       "        [5., 5.],\n",
       "        [5., 5.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x,x],dim = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.vstack is dim =0, torch.hstack dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 5., 5., 5., 5., 5., 5., 5., 5.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.]]]),\n",
       " torch.Size([2, 1, 3]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.zeros(2,1,3)\n",
    "x1,x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.squeeze(x1)\n",
    "x2,x2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 5., 5., 5., 5., 5., 5., 5., 5.])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5., 5., 5., 5., 5., 5.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr = x.reshape(1,9)\n",
    "xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 5., 5., 5., 5., 5., 5., 5., 5.])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.],\n",
       "        [5.],\n",
       "        [5.],\n",
       "        [5.],\n",
       "        [5.],\n",
       "        [5.],\n",
       "        [5.],\n",
       "        [5.],\n",
       "        [5.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = xr.squeeze()\n",
    "x3.unsqueeze(dim = 0) # (1,9)\n",
    "x3.unsqueeze(dim = 1) # (9,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.permute(x1,(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
